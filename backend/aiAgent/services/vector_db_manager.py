"""
Vector Database Manager
çµ±ä¸€ç®¡ç†æ‰€æœ‰å‘é‡è³‡æ–™åº«çš„åŸºç¤é¡åˆ¥
"""

import os
import numpy as np
import faiss
import torch
from datetime import datetime, timedelta
from django.conf import settings
from abc import ABC, abstractmethod


class BaseVectorDBManager(ABC):
    """å‘é‡è³‡æ–™åº«ç®¡ç†å™¨åŸºç¤é¡åˆ¥"""

    # éæœŸæ™‚é–“ï¼šç¦ç”¨è‡ªå‹•éæœŸï¼ˆæ”¹ç”¨å¢é‡æ›´æ–°ï¼‰
    EXPIRY_HOURS = None  # è¨­ç‚º None è¡¨ç¤ºä¸è‡ªå‹•éæœŸ

    def __init__(self, db_name, embedding_service, enable_expiry=False):
        """
        åˆå§‹åŒ–å‘é‡è³‡æ–™åº«ç®¡ç†å™¨

        Args:
            db_name (str): è³‡æ–™åº«åç¨±
            embedding_service: åµŒå…¥æœå‹™ï¼ˆBERT æˆ–å…¶ä»–ï¼‰
            enable_expiry (bool): æ˜¯å¦å•Ÿç”¨è‡ªå‹•éæœŸæª¢æŸ¥ï¼ˆé è¨­é—œé–‰ï¼‰
        """
        self.db_name = db_name
        self.embedding_service = embedding_service
        self.base_dir = settings.BASE_DIR
        self.enable_expiry = enable_expiry

        # å®šç¾©æª”æ¡ˆè·¯å¾‘
        self.emb_path = os.path.join(self.base_dir, f'{db_name}_embs.npy')
        self.ids_path = os.path.join(self.base_dir, f'{db_name}_ids.npy')
        self.metadata_path = os.path.join(self.base_dir, f'{db_name}_metadata.npy')

        # è¼‰å…¥æˆ–åˆå§‹åŒ–è³‡æ–™åº«
        self.load_or_initialize()

    def is_expired(self):
        """
        æª¢æŸ¥å‘é‡è³‡æ–™åº«æ˜¯å¦éæœŸ

        Returns:
            bool: True è¡¨ç¤ºå·²éæœŸï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
        """
        # å¦‚æœæœªå•Ÿç”¨éæœŸæª¢æŸ¥ï¼Œæ°¸é ä¸éæœŸ
        if not self.enable_expiry or self.EXPIRY_HOURS is None:
            return False

        if not os.path.exists(self.emb_path):
            return True

        # å–å¾—æª”æ¡ˆæœ€å¾Œä¿®æ”¹æ™‚é–“
        file_mtime = os.path.getmtime(self.emb_path)
        file_datetime = datetime.fromtimestamp(file_mtime)
        now = datetime.now()

        time_diff = now - file_datetime
        is_expired = time_diff > timedelta(hours=self.EXPIRY_HOURS)

        if is_expired:
            print(f"â° å‘é‡è³‡æ–™åº« {self.db_name} å·²éæœŸï¼ˆ{time_diff.total_seconds() / 3600:.1f} å°æ™‚ï¼‰ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–")

        return is_expired

    def check_and_refresh(self):
        """
        æª¢æŸ¥ä¸¦åˆ·æ–°éæœŸçš„å‘é‡è³‡æ–™åº«
        """
        if self.is_expired():
            print(f"ğŸ”„ é–‹å§‹é‡æ–°åˆå§‹åŒ– {self.db_name}...")
            self.embeddings = np.array([]).reshape(0, 768)
            self.ids = np.array([])
            self.metadata = np.array([])
            self.initialize_from_db()
            print(f"âœ… {self.db_name} é‡æ–°åˆå§‹åŒ–å®Œæˆ")

    def load_or_initialize(self):
        """è¼‰å…¥ç¾æœ‰è³‡æ–™åº«æˆ–åˆå§‹åŒ–æ–°çš„"""
        if os.path.exists(self.emb_path) and os.path.exists(self.ids_path):
            # æª¢æŸ¥æ˜¯å¦éæœŸï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.is_expired():
                print(f"âš ï¸ å‘é‡è³‡æ–™åº« {self.db_name} å·²éæœŸï¼Œæº–å‚™é‡æ–°åˆå§‹åŒ–...")
                self.embeddings = np.array([]).reshape(0, 768)  # BERT 768 ç¶­
                self.ids = np.array([])
                self.metadata = np.array([])
                self.initialize_from_db()
            else:
                # è¼‰å…¥ç¾æœ‰è³‡æ–™
                self.embeddings = np.load(self.emb_path)
                self.ids = np.load(self.ids_path)

                # å˜—è©¦è¼‰å…¥ metadata
                if os.path.exists(self.metadata_path):
                    self.metadata = np.load(self.metadata_path, allow_pickle=True)
                else:
                    self.metadata = np.array([])

                # é¡¯ç¤ºè¼‰å…¥è³‡è¨Š
                if self.enable_expiry and self.EXPIRY_HOURS:
                    file_mtime = os.path.getmtime(self.emb_path)
                    file_datetime = datetime.fromtimestamp(file_mtime)
                    age_hours = (datetime.now() - file_datetime).total_seconds() / 3600
                    remaining_hours = self.EXPIRY_HOURS - age_hours
                    print(f"âœ… è¼‰å…¥å‘é‡è³‡æ–™åº« {self.db_name}: {len(self.ids)} ç­†è³‡æ–™ï¼ˆå‰©é¤˜ {remaining_hours:.1f} å°æ™‚æœ‰æ•ˆï¼‰")
                else:
                    print(f"âœ… è¼‰å…¥å‘é‡è³‡æ–™åº« {self.db_name}: {len(self.ids)} ç­†è³‡æ–™ï¼ˆå¢é‡æ›´æ–°æ¨¡å¼ï¼‰")
        else:
            print(f"âš ï¸ å‘é‡è³‡æ–™åº« {self.db_name} ä¸å­˜åœ¨ï¼Œæº–å‚™åˆå§‹åŒ–...")
            self.embeddings = np.array([]).reshape(0, 768)  # BERT 768 ç¶­
            self.ids = np.array([])
            self.metadata = np.array([])
            self.initialize_from_db()

    @abstractmethod
    def initialize_from_db(self):
        """
        å¾è³‡æ–™åº«åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
        å­é¡å¿…é ˆå¯¦ä½œæ­¤æ–¹æ³•
        """
        pass

    @abstractmethod
    def get_text_for_embedding(self, item):
        """
        ç²å–ç”¨æ–¼ç”ŸæˆåµŒå…¥çš„æ–‡æœ¬
        å­é¡å¿…é ˆå¯¦ä½œæ­¤æ–¹æ³•

        Args:
            item: è³‡æ–™åº«é …ç›®

        Returns:
            str: ç”¨æ–¼åµŒå…¥çš„æ–‡æœ¬
        """
        pass

    def build_index(self, data_array):
        """
        å»ºç«‹å‘é‡ç´¢å¼•

        Args:
            data_array (list): è³‡æ–™é™£åˆ—ï¼Œæ¯å€‹å…ƒç´ åŒ…å« id å’Œ text
        """
        if not data_array:
            print(f"âš ï¸ {self.db_name} æ²’æœ‰è³‡æ–™å¯å»ºç«‹ç´¢å¼•")
            return

        print(f"ğŸ”¨ é–‹å§‹å»ºç«‹ {self.db_name} å‘é‡ç´¢å¼•...")
        batch_size = 4
        all_ids = []
        all_embeddings = []

        for i in range(0, len(data_array), batch_size):
            batch = data_array[i : i + batch_size]
            texts = [item['text'] for item in batch]
            ids = [item['id'] for item in batch]

            # ä½¿ç”¨ BERT ç”ŸæˆåµŒå…¥
            encoded = self.embedding_service.tokenizer(
                texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            ).to(self.embedding_service.device)

            with torch.no_grad():
                outputs = self.embedding_service.model(**encoded)
                embs = self.embedding_service._RecommendationService__mean_pooling(
                    outputs,
                    encoded.attention_mask
                )
                embs = torch.nn.functional.normalize(embs, p=2, dim=1)

            all_ids.extend(ids)
            all_embeddings.append(embs.cpu().numpy())

            if (i + batch_size) % 20 == 0:
                print(f"  è™•ç†é€²åº¦: {i + batch_size}/{len(data_array)}")

        self.ids = np.array(all_ids)
        self.embeddings = np.vstack(all_embeddings)

        # å„²å­˜ metadataï¼ˆå¯é¸ï¼‰
        if data_array and 'metadata' in data_array[0]:
            self.metadata = np.array([item['metadata'] for item in data_array])

        self.save()
        print(f"âœ… {self.db_name} å‘é‡ç´¢å¼•å»ºç«‹å®Œæˆ: {len(self.ids)} ç­†")

    def save(self):
        """å„²å­˜å‘é‡è³‡æ–™åº«åˆ°ç£ç¢Ÿ"""
        np.save(self.emb_path, self.embeddings)
        np.save(self.ids_path, self.ids)
        if len(self.metadata) > 0:
            np.save(self.metadata_path, self.metadata)
        print(f"ğŸ’¾ {self.db_name} å·²å„²å­˜")

    def add_item(self, item_id, text, metadata=None):
        """
        æ·»åŠ å–®å€‹é …ç›®åˆ°å‘é‡è³‡æ–™åº«

        Args:
            item_id (int): é …ç›® ID
            text (str): æ–‡æœ¬å…§å®¹
            metadata (dict): å…ƒæ•¸æ“šï¼ˆå¯é¸ï¼‰
        """
        # ç”ŸæˆåµŒå…¥
        encoded = self.embedding_service.tokenizer(
            [text],
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        ).to(self.embedding_service.device)

        with torch.no_grad():
            outputs = self.embedding_service.model(**encoded)
            emb = self.embedding_service._RecommendationService__mean_pooling(
                outputs,
                encoded.attention_mask
            )
            emb = torch.nn.functional.normalize(emb, p=2, dim=1)
            emb = emb.cpu().numpy()

        # æ·»åŠ åˆ°è³‡æ–™åº«
        if len(self.embeddings) == 0:
            self.embeddings = emb
        else:
            self.embeddings = np.vstack([self.embeddings, emb])

        self.ids = np.append(self.ids, item_id)

        if metadata:
            if len(self.metadata) == 0:
                self.metadata = np.array([metadata])
            else:
                self.metadata = np.append(self.metadata, metadata)

        self.save()
        print(f"â• æ·»åŠ é …ç›®åˆ° {self.db_name}: ID={item_id}")

    def delete_item(self, item_id):
        """
        å¾å‘é‡è³‡æ–™åº«åˆªé™¤é …ç›®

        Args:
            item_id (int): é …ç›® ID
        """
        if item_id in self.ids:
            idx = np.where(self.ids == item_id)[0][0]
            self.ids = np.delete(self.ids, idx)
            self.embeddings = np.delete(self.embeddings, idx, axis=0)

            if len(self.metadata) > 0:
                self.metadata = np.delete(self.metadata, idx)

            self.save()
            print(f"â– å¾ {self.db_name} åˆªé™¤é …ç›®: ID={item_id}")
        else:
            print(f"âš ï¸ é …ç›® ID {item_id} ä¸å­˜åœ¨æ–¼ {self.db_name}")

    def search(self, query_embedding, top_k=5, min_similarity=0.0):
        """
        å‘é‡ç›¸ä¼¼åº¦æœå°‹

        Args:
            query_embedding (np.array): æŸ¥è©¢å‘é‡
            top_k (int): è¿”å›æ•¸é‡
            min_similarity (float): æœ€å°ç›¸ä¼¼åº¦é–¾å€¼

        Returns:
            list: æœå°‹çµæœ
        """
        if len(self.embeddings) == 0:
            return []

        # å»ºç«‹ FAISS ç´¢å¼•
        dimension = self.embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)
        index.add(self.embeddings.astype(np.float32))

        # æœå°‹
        q = query_embedding.astype("float32").reshape(1, -1)
        distances, indices = index.search(q, k=min(top_k, len(self.ids)))

        # èª¿è©¦ï¼šé¡¯ç¤ºæ‰€æœ‰æœå°‹çµæœï¼ˆåŒ…æ‹¬è¢«é–¾å€¼éæ¿¾çš„ï¼‰
        print(f"      ğŸ” FAISS æœå°‹è¿”å› {len(indices[0])} å€‹çµæœï¼ˆé–¾å€¼å‰ï¼‰:")
        for i, idx in enumerate(indices[0]):
            if idx < len(self.ids):
                similarity = float(distances[0][i])
                passed = "âœ…" if similarity >= min_similarity else "âŒ"
                metadata_str = ""
                if len(self.metadata) > 0:
                    meta = self.metadata[idx]
                    metadata_str = f"æ¡ˆä¾‹ {meta.get('archive_id', 'N/A')}"
                print(f"        {passed} {metadata_str}: ç›¸ä¼¼åº¦={similarity:.3f} (é–¾å€¼={min_similarity})")

        # æ ¼å¼åŒ–çµæœ
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.ids):
                similarity = float(distances[0][i])
                if similarity >= min_similarity:
                    result = {
                        'id': int(self.ids[idx]),
                        'similarity': similarity
                    }
                    # åŠ å…¥ metadataï¼ˆå¦‚æœæœ‰ï¼‰
                    if len(self.metadata) > 0:
                        result['metadata'] = self.metadata[idx]
                    results.append(result)

        return results

    def get_stats(self):
        """ç²å–è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        return {
            'name': self.db_name,
            'total_items': len(self.ids),
            'embedding_dim': self.embeddings.shape[1] if len(self.embeddings) > 0 else 0,
            'has_metadata': len(self.metadata) > 0,
            'file_exists': os.path.exists(self.emb_path)
        }